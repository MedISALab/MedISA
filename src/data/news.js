export const news = [
  {
    title: "Feature-driven layer specialization for label heterogeneous federated learning",
    authors: ["Obed Jamir", "Angshuman Paul"],
    year: 2026,
    description: "Federated Learning (FL) has redefined how models are trained across distributed systems by enabling decentralized training without compromising data privacy. This allows organizations and institutions with sensitive information to collaborate effectively while ensuring confidentiality. However, diversity in client data distributions poses unique challenges that require innovative solutions. Recent advances in FL have shown promising results by tailoring personalized models for each client’s data distribution, but very few methods address the complexities introduced by label heterogeneity. Existing methods require clients to share their class labels with the server to build a homogeneous label distribution for all clients. However, this may not be possible for clients with strict privacy regulations, such as medical institutions. In this study, we introduce a novel approach to manage label heterogeneity across clients without sharing labels. Our method dynamically separates client models into general and specialized layers to accommodate client-agnostic and client-specific features, respectively. In each communication round, the general layers are updated with the parameters of the global model, while the specialized layers are preserved. This selective layer update is followed by fine-tuning of specialized layers for each client model to better adapt to the client’s local data distribution while exploiting shared representations through the general layers. Experimental evaluations on publicly available chest X-ray and natural image datasets demonstrate that our method outperforms several state-of-the-art FL techniques.",
    published: "Neurocomputing"
  },
  {
    title: "Class-incremental learning using push-pull autoencoder for chest X-ray diagnosis",
    authors: ["Jayant Mahawar", "Angshuman Paul"],
    year: 2025,
    description: "Class-incremental learning helps models adapt to new classes without past data. This supports long-term learning. In medical imaging, it integrates new diseases or imaging methods over time. CIL models for natural images struggle in chest x-rays diagnosis. Conversely, deep learning models that excel in chest x-ray diagnosis tend to suffer from catastrophic forgetting in a class-incremental setting. To address this, we propose a novel class-incremental learning framework specifically designed for chest x-ray analysis. Our approach utilizes both abnormality-specific and abnormality-agnostic information from the input data. We designed a model, the Push-Pull Autoencoder (PPAE), that uses a dual latent space representation to refine feature representations by disentangling abnormality-specific from abnormality-agnostic information. This enhances the model’s understanding of disease features. PPAE is trained in such a way that it brings the training samples closer together based on shared, abnormality-agnostic features, while simultaneously distinguishing them using abnormality-specific features. To retain critical knowledge without exhaustive retraining, we employ a coreset generation algorithm that selects representative exemplars from previous classes. This approach maintains diagnostic accuracy on previously learned diseases while adapting seamlessly to new classes. PPAE addresses the problem of catastrophic forgetting prominent in class-incremental learning. Experimental results show up to 3% improvement in terms of F1 score and up to 4% improvement in terms of AUROC across various chest x-ray datasets. It validates the robustness of our framework in incremental learning tasks, highlighting its potential to advance continuous chest x-ray diagnosis.",
    published: "Computers in Biology and Medicine"
  },
  {
    title: "Test-Time Adaptation through Semantically-guided Feature Decomposition for Few-shot Chest X-ray Diagnosis",
    authors: ["Jayant Mahawar", "Angshuman Paul"],
    year: 2025,
    description: "Training a deep neural network with a small amount of labeled data is challenging. The challenge is even more severe for medical images because of the many possible variations in the images. We propose a novel framework for few-shot chest x-ray (CXR) diagnosis. For classification problems, training with limited data may be facilitated if class-specific features can be extracted and utilized. Semantic information about the abnormalities may also be helpful in this context. To that end, we design an autoencoder-based approach that extracts visual features and decomposes them into class-agnostic and class-specific features utilizing the semantic information of the abnormalities. The decomposition helps in efficient classification using the class-specific features. Additionally, we perform test-time adaptation to deal with possible variations in the test data compared to the training data. From this perspective, our method is one of the first of its kind. Extensive evaluations on publicly available chest x-ray datasets under few-shot settings show the effectiveness of our method. Results on the publicly available chest x-ray datasets show a 3–5% improvement in AUROC scores.",
    published: "IEEE/CVF Winter Conference on Applications of Computer Vision"
  }
];
/*
  {
    title: "Traffic Forecasting using Deep Sequence Models with Vehicle Situation-aware Loss",
    authors: ["Akash Chatterjee", "Jayant Mahawar", "Angshuman Paul"],
    year: 2025,
    description: "Accurate traffic forecasting is crucial for modern intelligent transportation systems. Deep sequence models have shown great promise in trajectory prediction tasks, as they are capable of capturing temporal dependencies and learning complex motion dynamics. However, most existing approaches primarily focus on predicting only the velocity of the concerned vehicle. Even models that account for neighboring vehicles are often trained solely with velocity-based loss functions, without incorporating other crucial factors such as lane changes or varying traffic density. This could lead to the model being over-reliant on spurious correlations and having a limited behavioral understanding. To address this gap, we introduce a novel, composite loss function called Vehicle Situation-aware Loss (VSAL), which enables deep models to learn multiple interrelated traffic variables simultaneously. VSAL integrates distinct loss components such as velocity and position, geospatial accuracy, and lane-change classification. It also includes a self-consistency term to ensure that the predicted velocity and the predicted displacement for the vehicle are coherent. We apply VSAL to enhance three state-of-the-art sequence models (LSTM, GRU, and Transformer), creating the improved VS-LSTM, VS-GRU, and VS-Transformer variants. These models are trained on rich contextual features, including lane-specific gap distances and a novel Jam Factor. Our experiments demonstrate that the VS-models consistently and substantially outperform their baseline counterparts. Notably, the VS-Transformer achieves a remarkable velocity RMSE of 0.002, representing a substantial improvement over the baseline. The framework also achieves a low Haversine RMSE of 0.358 and a robust lane-change classification accuracy of over 77.20%.",
    published: "Conference on Computer Vision and Image Processing"
  },
  {
    title: "LearnDiff: MRI image super-resolution using a diffusion model with learnable noise",
    authors: ["Sagnik Goswami", "Akriti Gupta1", "Angshuman Paul"],
    year: 2025,
    description: "MRI images with a superior spatial resolution may facilitate an accurate and faster diagnosis. We present LearnDiff, a diffusion probabilistic model with learnable noise for the super-resolution of MRI images. Unlike the standard diffusion models that rely on a fixed, standard normal distribution, LearnDiff utilizes a learnable Gaussian distribution in the diffusion bottleneck, enabling both forward and reverse processes to adapt dynamically. This flexibility addresses a critical limitation. A standard normal distribution for noise may not be adequate in the context of MRI super-resolution using a residual approach. By allowing the noise distribution to be learnable, our model achieves SOTA performance on publicly available MRI images, showing a 3.8% improvement in PSNR compared to previous SOTA methods, significantly outperforming traditional diffusion models. Across multiple MRI datasets, our approach yields superior image quality and enhanced quantitative metrics, highlighting its effectiveness in capturing finer image details and achieving more accurate super-resolution.",
    published: "Computerized Medical Imaging and Graphics"
  },
  {
    title: "Few-Shot Diagnosis of Chest X-Ray Images using Auxiliary Information Guided Semideterministic Infinite Mixture Prototypes",
    authors: ["Prabhala Sandhya Gayatri", "Devi Prasad Maharathy", "Angshuman Paul"],
    year: 2025,
    description: "This paper proposes a few-shot learning (FSL) approach for diagnosing chest X-ray images, designed to work effectively with limited annotated data. The method utilizes auxiliary semantic information related to various chest abnormalities, enabling the model to learn more efficiently and improve diagnostic accuracy even in data-scarce scenarios. A major challenge addressed by this work is the variation in visual characteristics of the same abnormality across different X-ray images. Factors such as patient anatomy, imaging conditions, and disease progression can cause significant differences in how an abnormality appears. Traditional approaches often assume that data points with the same abnormality form a single cluster based solely on visual features, which is ineffective for multi-label datasets where images can contain multiple abnormalities with diverse patterns. To tackle this issue, the authors introduce a semi-deterministic infinite mixture prototype method that dynamically generates multiple clusters for each abnormality. This allows the model to capture the full range of visual variations associated with a condition. Importantly, the clustering process is guided by semantic information, which helps in creating more discriminative and meaningful representations of chest X-ray images. The proposed method was evaluated on publicly available chest X-ray datasets, demonstrating superior performance in identifying and classifying abnormalities with limited training data. By combining few-shot learning with semantic guidance, this approach offers a scalable and accurate solution for medical image analysis",
    published: "Computers in Biology and Medicine"
  },
  {
    title: "Distribution-guided Generative Replay with Semantic Prompts for Class-Incremental Chest X-ray Diagnosi",
    authors: ["Jayant Mahawar", "Devi Prasad Maharathy", "Angshuman Paul"],
    year: 2025,
    description: "Existing class-incremental learning (CIL) methods perform poorly for the diagnosis of medical images. Some CIL approaches require storing exemplars, which raises privacy and storage concerns. Others rely on unconditioned generative replay, compromising discriminative power. To overcome these issues, we propose a new CIL framework for chest x-ray (CXR) diagnosis that combines prompt tuning with distribution-guided generative replay at the feature level. The prompts are initialized with semantically rich embeddings and refined through training. A variational autoencoder captures the feature distribution in latent space, enabling past knowledge retention without storing raw data. To balance stability and plasticity, parts of the network are frozen after the initial phase while others adapt to new classes. In each session, the model learns new classes using real data and replays the synthetic features of old ones to reduce forgetting. A classification module picks the closest class prompt using cosine similarity. We evaluate our method on public CXR datasets. It outperforms prior CIL methods in accuracy and retention. We achieve up to 9\% improvement in average accuracy compared to SOTA methods",
    published: "The 36th British Machine Vision Conference"
  },
  {
    title: "Knowledge Distillation for an Ensemble of Students from a Pyramid of Teachers with Diverse Perspective",
    authors: ["Shilajit Banerjee", "Angshuman Paul"],
    year: 2025,
    description: "Knowledge distillation (KD) can be used for enhancing the performance of a lightweight student models with the help of knowledge from heavier teacher models. Most KD methods for classification use a one-teacher one-student architecture where only one teacher is responsible for transferring knowledge to a student for all the classes. However, when the number of classes increases, it may become difficult for a single teacher to learn the salient characteristics of all the classes. This may also adversely affect the performance of a student in a KD approach. In this paper, we present a novel KD method where an ensemble of lightweight students is trained by a pyramid of teachers. At the top level of the pyramid, we have one teacher that learns all the class labels under consideration. As we go down the pyramid, the number of teachers increases at each level. However, except for the top level, each teacher learns a smaller subset of classes compared to its upper levels. Hence, different teachers learn different perspectives of the classification problem. Also, as we move down the pyramid, the teachers become more and more specialized. On the contrary, as we move upward, the teachers learn a broader and broader perspective about the classification problem. We design a novel distillation loss to distill the knowledge between the student and the pyramid of teachers. Experimental results on publicly available datasets show the effectiveness of the proposed method.",
    published: "IEEE Transactions on Artificial Intelligence"
  },
  */